{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie głębokie cz. II\n",
    "\n",
    "Ten notatnik ma na celu przedstawienie sposobów wykorzystania uczenia głębokiego w różnych zastosowaniach. W trakcie zadania najpierw dostosujemy istniejącą sieć konwolucyjną do nowych danych, zobaczymy jak stosować sieci do rekomendowania produktów oraz jak nauczyć klasyfikator tekstowy. Na tych zajęciach wykorzystamy bibliotekę [fast.ai](https://github.com/fastai/fastai), która jest wrapperem na [PyTorch](https://pytorch.org/) oraz, tak jak ostatnio, [Keras](https://keras.io/). Poniższe skrytpty są w istocie kompilacją różnych materiałów szkoleniowych do fast.ai i Kerasa.\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ wiedzieć dostosować istniejącą architekturę (wraz z wagami) do własnego problemu, \n",
    "+ wiedzieć jak zamrażać i odmrażać warstwy sieci,\n",
    "+ umieć zastosować sieć neuronową do danych tekstowych,\n",
    "+ potrafić stowrzyć własny model rekomendacyjny oparty o sieć neuronową."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie środowiska na Crestle\n",
    "\n",
    "Ćwiczenie wykonamy na platformie [Crestle](https://www.crestle.com), aby nie musieć instalować bibliotek i zbiorów danych lokalnie. \n",
    "\n",
    "Po zalogowaniu na Crestle wgraj tego notebooka do folderu\n",
    "\n",
    "```\n",
    "/courses/fastai/\n",
    "```\n",
    "\n",
    "Gdy wgrasz notebooka, zacznij od odpalenia poniższej komendy, aby korzystać z najnowszej wersji fast.ai. fast.ai wciąż jest w wersji alfa, więc najlepiej korzystać bezpośrednio z wersji na githubie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ przykłady są trudne i uczenie sieci trwa długo (nawet na GPU) każdy wykona tylko jedno z poniższych zadań:\n",
    "- **Rozpoznawanie obrazów**\n",
    "- **Tworzenie systemu rekomendacyjnego**\n",
    "- **Analiza tekstu**\n",
    "\n",
    "W chwilach, gdy sieć się uczy i jest parę minut wolnego możesz zajrzeć do sąsiada, który wykonuje inne zadanie i wymienić się uwagami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozpoznawanie obrazów\n",
    "\n",
    "Spróbujemy nauczyć sieć rozpoznającą typy terenu na zdjęciach satelitarnych. W tym celu wykorzystamy sieć nauczoną na zbiorze danych ImageNet, która umie klasyfikaować pojedyncze obiekty na zdjęciach (psy, koty, czołgi, itp.). W naszym problemie będziemy musieli rozpoznać kilka rodzajów terenu na każdym zdjęciu (multi-label classification) i nie będą one przypominały obiektów ze zbioru ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane\n",
    "\n",
    "Dane pochądzą z zakończonego konkursu na Kaggle o nazwie [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space). Dane są już wgrane na naszej instancji na Crestle. Musimy tylko odpowiednio ułożyć dane w foldery.\n",
    "\n",
    "Wykorzystamy opcję wywoływania poleceń systemowych w Jupyter (`!<komenda>`) do utworzenia linków symbolicznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "PATH = 'data/planet/'\n",
    "\n",
    "os.makedirs('data/planet/models', exist_ok=True)\n",
    "os.makedirs('/cache/planet/tmp', exist_ok=True)\n",
    "\n",
    "!ln -s /datasets/kaggle/planet-understanding-the-amazon-from-space/train-jpg {PATH}\n",
    "!ln -s /datasets/kaggle/planet-understanding-the-amazon-from-space/test-jpg {PATH}\n",
    "!ln -s /datasets/kaggle/planet-understanding-the-amazon-from-space/train_v2.csv {PATH}\n",
    "!ln -s /cache/planet/tmp {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli porządki się udały zobaczmy jak wyglądają dwa przykładowe zdjęcia satelitarne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.plots import *\n",
    "\n",
    "list_paths = [f\"{PATH}train-jpg/train_0.jpg\", f\"{PATH}train-jpg/train_1.jpg\"]\n",
    "titles=[\"haze primary\", \"agriculture clear primary water\"]\n",
    "plots_from_files(list_paths, titles=titles, maintitle=\"Multi-label classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdjęcie po lewej ma etykiety (klasy) *haze* i *primary*, a zdjęcie po prawej ma etykiety *agriculture*, *clear*, *primary* i *water*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dostosowywanie sieci\n",
    "\n",
    "W pierwszej kolejności ustalimy sposób ładowania danych do sieci i miarę oceny, którą będziemy śledzić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from sklearn.metrics import fbeta_score\n",
    "import warnings\n",
    "\n",
    "label_csv = f'{PATH}train_v2.csv' # plik csv z połączeniem nazwa_obrazu-etykiety\n",
    "n = len(list(open(label_csv)))-1 # liczba przykładów\n",
    "val_idxs = get_cv_idxs(n) # numery przykładów które weźmiemy do oceny krzyżowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1.1: Sprawdź ile przykładów ma cały zbiór danych i ile z tych przykładów zostało odłożonych jako przykłady walidacyjne.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz czas na miarę oceny. W konkursie liczona była miara F2. To prawie to samo co F1-score, o którym kiedyś wspominaliśmy, tylko precision i recall mają nierówne wagi w średniej harmonicznej.\n",
    "\n",
    "Choć sama miara może Cię nie interesować, to zwróć uwagę, że możesz śledzić wynik dowolnej funkcji, która przyjmuje dwa parametry:\n",
    "- `preds` predykcje,\n",
    "- `targs` prawdziwe etykiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(preds, targs, start=0.17, end=0.24, step=0.01):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n",
    "                    for th in np.arange(start,end,step)])\n",
    "    \n",
    "metrics = [f2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz najważniejsze. Nie będziemy podawać do sieci naszych obrazów od tak. Będziemy dane losowo modywfikować. Operacja ta po angielsku nosi nazwę *data augmentation* i w przypadku zdjęć z reguły obejmuje:\n",
    "- obroty\n",
    "- pomniejszanie obrazów\n",
    "- zoom\n",
    "- przesunięcia lewo/prawo\n",
    "- lustrzane odbicia\n",
    "\n",
    "Takie transformacje kryją się w bibliotece fast.ai pod akronimem `tfms` (od transformations). Funkcja `tfms_from_model` jest odpowiedzialna za wykonywanie transformacji oraz przystosowywanie sieci do nowych danych, czyli inicjalizację oraz normalizację wag wejściowych przy pierwszym uczeniu.\n",
    "\n",
    "Na koniec za pomocą klasy `ImageClassifierData` tworzymy generator danych wejściowych do sieci (tzw. DataModel). Już kiedyś o tym wspominaliśmy, ale w ramach przypomnienia: generator w Pythonie to iterator, czyli w praktyce funkcja która zamiast zwracać całą listę iobiektów od razu, potrafi to robić po jednym obiekcie naraz.\n",
    "\n",
    "**Zad. 1.2: Poniżej stworzymy metodę, która będzie generowała dane o zadanym rozmiarze `sz`. Spróbuj określić jakie inne transformacje będą wykonywane na obrazach.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model = resnet34\n",
    "\n",
    "def get_data (sz):\n",
    "    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n",
    "    return ImageClassifierData.from_csv(PATH, 'train-jpg', label_csv, tfms=tfms,\n",
    "                    suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz przechodzimy do wykorzystania istniejącej sieci. fast.ai zawiera szereg gotowych architektur takich VGG, Resnet, Resnext. Można skorzystać z samej architektury lub z architektury wraz ze wstępnie wyuczonymi wagami (ang. *pretrained*). Jak widać w bloku powyżej, my skorzystamy z architektury resnet34, która jest jedną z nowszych i szybszych architektur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie\n",
    "\n",
    "Skorzystamy z architektury wraz ze wstępnie wyuczonymi wagami. Taki wstępnie nauczony model ma zamrożone wagi. fast.ai sam dodaje za nas ostatnie warstwy, które będą stanowić model i będą odmrożone.\n",
    "\n",
    "Aby przyspieszyć proces dostosowywania sieci można skorzystać z następującej sztuczki. Zmniejszymy obrazy do rozmiaru 64X64 żeby sieć była mniejsza i uczenie szło szybciej. Żeby jeszcze przyspieszyć początkowe uczenie wygenerowane dane (zmniejszone, lustrzane odbicia, itd.) zapiszemy do osobnych plików (w folderze `tmp`), żeby nie tracić czasu na generowanie ich w locie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz=64\n",
    "data = get_data(sz)\n",
    "data = data.resize(int(sz*1.3), 'tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz magia fast.ai: prosimy o wstępnie wyuczony model (`ConvLearner.pretrained`), o zadanej architekturze (`f_model`), do przetwarzania naszych danych (`data`) i śledzenia wskazanego przez nas zbioru miar (`metrics`). Zwróć uwagę, że nie definiujemy żadnych warstw, funkcji aktywacji, optymalizatora czy funkcji straty. fast.ai pozwala na ustawienie tych rzeczy, ale celem tej biblioteki jest zaoferowanie dobrych wartości domyślnych i ustawienie większości parametrów za nas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(f_model, data, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią rzeczą, którą musimy zrobić to określić learning rate. fast.ai promuje heurystykę do znajdowania tej wartości. W skrócie: przetestuj wiele różnych learning rate i wybierz tę wartość, która powoduje największe tempo obniżania wartości funkcji straty.\n",
    "\n",
    "Odpal poniższy kod, przyjrzyj się wykresowi i prównaj z wartością `lr` w kolejnej komórce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, wybraliśmy learning rate, teraz przechodzimy do faktycznego uczenia. Odpalamy `fit` podając jako parametry:\n",
    "- liczbę cykli uczenia\n",
    "- liczbę epok w pierwszym cyklu\n",
    "- ile razy dłuższe mają być kolejne cykle\n",
    "\n",
    "W naszym przypadku mamy trzy cykle, każdy dwa razy dłuższy, czyli: 1 + 2 + 4 = 7. Ta sztuczka z tworzeniem cykli uczenia nazywa się Stochastic Gradient Descent with Restarts (SGDR) i możecie o niej poczytać np. [tutaj](https://arxiv.org/abs/1608.03983).\n",
    "\n",
    "Dość gadania. Zacznijmy uczyć sieć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz odmrozimy (`unfreeze`) wcześniejsze warstwy sieci i nadamy osobne learning rate (`lrs`) dla każdego z trzech fragmentów sieci resnet.\n",
    "\n",
    "Zwróć uwagę, że najmniej chcemy zmieniać wagi w początkowych warstwach sieci (`lr/9`) a najbardziej w ostatnich (`lr`). Pierwsze warstwy we wstępnie wyuczonej sieci konwolucyjnej wykrywają takie cechy jak krawędzie czy kolory i wag w tych warstwach nie chcemy zbytnio zmieniać. Ostatnie warstwy to z kolei nasz model, który musimy uczyć od zera stąd potrzeba szybszego tempa zmian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lrs = np.array([lr/9,lr/3,lr])\n",
    "\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n",
    "learn.save(f'{sz}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróć uwagę, że zapisaliśmy model do pliku. To taki środek bezpieczeństwo gdybyśmy musieli z jakiegoś powodu przerwać uczenie na jakiś czas. Oprócz możliwości zapisu do pliku, obiekt learn ma szereg innych przydatnych informacji. Możemy np. narysować krzywą uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A teraz zwiększymy obrazy do 128x128 i powtórzymy tę samą sztuczkę. Najpierw douczymy ostatnie warstwy, a potem odmrozimy wcześniejsze i zaktualizujemy im wagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz=128\n",
    "\n",
    "learn.set_data(get_data(sz))\n",
    "learn.freeze()\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n",
    "learn.save(f'{sz}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1.3: Powtórz powyższą operację dla obrazów w pełnej rozdzielczości, czyli 256x256.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "Podobną metodologię, obejmującą generowanie sztucznych danych wraz z wykorzystaniem istniejącej architektury i wag, można oczywiście zaimplementować również w Kerasie. Krótki tutorial jak to zrobić znajdziesz na stronie: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System rekomendacyjny\n",
    "\n",
    "Sieci neuronowe są tak ogólnym narzędziem, że można je wykorzystać do wielu różnych zadań. Jednym z takich zadań, o którym jeszcze nie mówiliśmy, jest rekomendowanie produktów. Jednym ze sztandarowych algorytmów do tego problemu jest [collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering).\n",
    "\n",
    "Ogólna idea algorytmu to estymacja oceny produktu przez klienta na podstawie:\n",
    "- podobieństwa tego klienta do innych osób które już oceniły dany produkt,\n",
    "- podobieństwa tego produktu do innych produktów, które ocenił klient.\n",
    "\n",
    "W najprostzej formie sprowadza się to do ważenia wektora klientów i produktów w taki sposób by uzyskać oceny. Poprosimy, żeby fast.ai zrobił dla nas coś podobnego z wykorzystaniem sieci neuronowych do określenia wag produktów i klientów.\n",
    "\n",
    "### Przygotowanie danych\n",
    "\n",
    "Zaczniemy od ściągnięcia zbioru danych. Do ćwiczenia wykorzystamy podzbiór recenzji filmów ze strony [movielens](https://movielens.org/). Odpal poniższy kod, aby załadować dane do folderu `data` na Crestle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O ./data/ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz rozpakujemy zbiór danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./data/ml-latest-small.zip -d ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Teraz zaimportujemy parę bibliotek, które będą nam potrzebne i zobaczmy jak wygląda zbiór uczący."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "from fastai.column_data import *\n",
    "import seaborn as sns\n",
    "\n",
    "path = 'data/'\n",
    "ratings = pd.read_csv(path + 'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super. Mamy identyfikatory filmów i użytkownków oraz oceny od 1 do 5. Ponieważ będziemy chcieli śledzić proces uczenia się sieci, określimy, że część przykładów będzie zbiorem walidacyjnym. W tym celu skorzystamy z funkcji `get_cv_idxs` z biblioteki fast.ai.\n",
    "\n",
    "**Zad. 2.1: Sprawdź ile przykładów ma cały zbiór danych i ile z tych przykładów zostało odłożonych jako przykłady walidacyjne.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie modelu\n",
    "\n",
    "Nie będziemy musieli dużo robić żeby stworzyć mdel przewidujący oceny filmów. Musimy tylko określić kilka parametrów. W ramach ćwiczenia od razu podamy dość dobre wartości, ale normalnie trzeba by było dobrać je metodą prób i błędów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=2e-4        # weight decay, czyli stała regularyzacji - parametr pilnujący żeby sieć nie przeuczyła się za szybko\n",
    "n_factors = 50 # głębokość embeddingu, czyli za pomocą ilu liczb (wag) wyrazimy jednego użytkownika czy jeden film\n",
    "batch=64       # grupa przykładów, które przepuszczamy przez sieć między etapami propagacji wstecznej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz stworzymy sieć. W fast.ai definicja sieci jest powiązana ze zbiorem danych (nazywają to `DataModel`). My skorzystamy z `CollabFilterDataset` i stworzymy taki model w oparciu o plik csv. W kolejnych prametrach podamy, które kolumny odpowiadają za klientów (użytkowników), produkty (filmy) i ocenę.\n",
    "\n",
    "Następnie w opaciu o DataModel poprosimy fast.ai o sieć, którą zapiszemy to zmiennej `learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CollabFilterDataset.from_csv(path, 'ratings.csv', 'userId', 'movieId', 'rating')\n",
    "learn = cf.get_learner(n_factors, val_idxs, batch, opt_fn=optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatni krok to puszczenie uczenia.\n",
    "\n",
    "**Zad. 2.2: Spróbuj określić co oznaczają kolejne parametry metody `fit()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 2, wds=wd, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 2.3: Wynik który dostałeś (ok. 0.776) to MSE (funkcja straty, którą za Ciebie określił fast.ai). Wylicz RMSE, aby oszacować o ile średnio model myli się w swojej ocenie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec zwizualizujemy sobie predykcje. Wykorzystamy do tego bibliotekę seaborn, którą możesz kojarzyć z jednych z wcześniejszych zajęć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.predict()\n",
    "\n",
    "y=learn.data.val_y\n",
    "sns.jointplot(preds, y, kind='hex', stat_func=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 2.4: Zmień zwiększ batch size i liczbę epok (cykli). Porównaj wyniki.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie języka naturalnego\n",
    "\n",
    "Spróbujemy teraz stworzyć sieć do przewidywania tematyki tekstu. Przyjmiemy następującą strategię:\n",
    "- najpierw skorzystamy z gotowych word embeddings (tych samych o których mówiliśmy parę zajęć temu),\n",
    "- stworzymy sieć, w której word embeddings będą tworzyć periwszą warstwę,\n",
    "- nauczymy tak sklejoną sieć przewidywać jedną z 20 klas w zbiorze uczącym.\n",
    "\n",
    "To zadanie wykonamy wyjątkowo w Keras. Tak jak zwykle, parę bibliotek na początek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych\n",
    "\n",
    "Jako word embedding wykorzystamy model GloVe oparty o 6 miliardów tekstów. Oficjalną stroną dla tego modelu jest: https://nlp.stanford.edu/projects/glove/.\n",
    "\n",
    "Jako zbiór danych do naszych eksperymentów wykorzystamy zbiór `newsgroup`. Jest to dosyć stary zbiór danych posiadający teksty obejmujące 20 różnych tematów. Zbiór nie jest zbyt duży dzięki czemu jest szansa nauczyć model nawet lokalnie.\n",
    "\n",
    "Poniższy kod zawiera ścieżki, w których będziemy oczekiwać embeddings i danych. Ponadto ustawimy kilka parametrów, które wykorzystamy później."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './data/'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A teraz ściągnijmy potrzebne dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O ./data/glove.6B.zip http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!wget -O ./data/news20.tar.gz http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozkakujmy paczkę z word embeddings. Zajmie sporo miejsca, ale powinna rozpakować się dosyć szybko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./data/glove.6B.zip -d ./data/glove.6B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto wspomnieć, że w Internecie można znaleźć gotowe word embeddings dla różnych języków. Poniżej pierwsze dwa trafienia dla języka niemieckiego:\n",
    "- https://devmount.github.io/GermanWordEmbeddings/\n",
    "- https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "Dobra. Teraz przeiterujemy przez cały zestaw word embeddings i stworzymy **słownik**, gdzie kluczem będzie **słowo** a wartością wektor liczb reprezentujących **embedding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Super, mamy %s embeddingsów.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3.1: Ile liczb jest powiązanych z jednym słowem w ramach jednego word embedding?**\n",
    "\n",
    "Teraz rozpakujemy zbiór danych newsgroup. To niestety potrwa dosyć długo - choć zbiór nie jest taki duży, to składa się z wielu tysięcy plików."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/news20.tar.gz -C ./data # to trochę potrwa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz przejedziemy przez zbiór danych i wyłuskamy listę tekstów oraz wektor etykiet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []  # lista tekstów (atrybuty opisowe)\n",
    "labels_index = {}  # słownik mapujący klasę na liczbę (identyfikator klasy)\n",
    "labels = []  # lista etykiet (atrybut decyzyjny) \n",
    "\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
    "                with open(fpath, **args) as f:\n",
    "                    t = f.read()\n",
    "                    i = t.find('\\n\\n') \n",
    "                    if 0 < i:\n",
    "                        t = t[i:]\n",
    "                    texts.append(t)\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Mamy %s tekstów.' % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak się składa, że Keras oferuje własny tokenizator. Pozwoli on nam podzielić tekst na słowa i zachować tylko najpopularniejsze wyrazy (`MAX_NUM_WORDS`). Najperw odpalimy `fit`, żeby określić najpopularniejsze słowa, a następnie faktycznie stokenizujemy teksty za pomocą `texts_to_sequences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Mamy %s unikatyowych tokenów.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ większość sieci lubi wejście w konkretnym rozmiarze, skorzystamy z funkcji `pad_sequences` aby ustandaryzować wejście. Za długie sekwencje słów przytniemy, a za krótkie uzupełnimy putymi znakami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako ostatni krok przygotowania, standardowe czynności:\n",
    "- kodowanie etykiet w sposób binarny,\n",
    "- podział na dane uczące i walidacyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie\n",
    "\n",
    "Teraz po tym całym przetwarzaniu danych spróbujemy stworzyć klasyfikator. Najpierw wykorzystamy nasze word embeddings z Glove żeby stworzyć pierwszą warstwę sieci. Ponieważ ograniczyliśmy słownik do `MAX_NUM_WORDS`, nasza warstwa będzie miała co najwyżej tyle wag.\n",
    "\n",
    "Pozostaje nam tylko zmapować identyfikator słowa z jego embedding, żeby zainicjalizować wagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz stworzymy własną sieć. Zwróć uwagę, że korzystamy z 1-wymiarowych konwolucji, czyli \"filtra\" który przesuwa się po kolejnych grupach słów. Tak dla przypomnienia konwolucje 2D przesuwały kwadratowy filtr po obrazie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I uczymy sieć..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3.2: Podłącz sieć do Tensorboarda i wypróbuj innych parametrów lub archotektur**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobne (choć nie identyczne) podejście można zaimplementować w fast.ai. Na stronie [githubie fast.ai](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson4-imdb.ipynb) można prześledzić jak stworzyć generator tekstu, którego wagi (embeddings) później zostaną wykorzystane do klasyfikacji. Sieci wykorzystane w tym przykładzie są inne, ale idea dwuetapowego rozwiązywania problemu analizy tekstu pozostaje. Przykład z fast.ai pokazuje znacznie silniejszy model, ale wymaga przy tym znacznie więcej czasu na wgryzienie się w kod."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
