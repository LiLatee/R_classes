{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "\n",
    "Ten notatnik ma na celu przedstawienie sposobu tworzenia i wykorzystania reprezentacji werktorowych na przykładzie algorytmu word2vec. W trakcie zadania najpierw stworzymy prostą reprezentację wektorową, a następnie spróbujemy wczytać gotowy model nauczony na dużym korpusie tekstowym.\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ wiedzieć na czym polega word2vec,\n",
    "+ potrafić stworzyć word2vec na własnych danych,\n",
    "+ potrafić wykorzystać word2vec do:\n",
    "\t+ znalezienia podobnych słów,\n",
    "\t+ wyszukiwania słów na zasadzie \"reguły trzech\", \n",
    "\t+ wykrywania niepasujących słów,\n",
    "\t+ do tworzenia wektora cech nadającego się do klasyfikacji,\n",
    "+ wczytać i wykorzystać gotowy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosty model\n",
    "\n",
    "Najpierw wczytamy odpowiednie biblioteki i stworzymy mały zbiór treningowy na podstawie znanej piosenki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, re, nltk\n",
    "import pandas as pd\n",
    "\n",
    "RE_SPACES = re.compile(\"\\s+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "song = \"\"\"Gdzie strumyk płynie z wolna,\n",
    "Rozsiewa zioła maj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Zielony gaj.\n",
    "\n",
    "W tym gaju tak ponuro,\n",
    "Że aż przeraża mnie,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "samotnej źle.\n",
    "\n",
    "Wtem harcerz idzie z wolna.\n",
    "„Stokrotko, witam cię,\n",
    "Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?”\n",
    "\"Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?\n",
    "Czy nie, czy nie?\n",
    "\n",
    "Stokrotka się zgodziła\n",
    "I poszli w ciemny las,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "w pokrzywy wlazł.\n",
    "\n",
    "A ona, ona, ona,\n",
    "Cóż biedna robić ma,\n",
    "Nad gapą pochylona\n",
    "I śmieje się: ha, ha,\n",
    "Nad gapą pochylona\n",
    "I śmieje: się ha, ha,\n",
    "ha, ha, ha, ha.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1: Podziel piosenkę na wersy, a wersy tokenizuj spacjami. W efekcie powinieneś stworzyć listę list i przypisać ją do zmiennej `sentences`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gdzie', 'strumyk', 'płynie', 'z', 'wolna,'], ['Rozsiewa', 'zioła', 'maj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Zielony', 'gaj.'], [''], ['W', 'tym', 'gaju', 'tak', 'ponuro,'], ['Że', 'aż', 'przeraża', 'mnie,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['samotnej', 'źle.'], [''], ['Wtem', 'harcerz', 'idzie', 'z', 'wolna.'], ['„Stokrotko,', 'witam', 'cię,'], ['Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?”'], ['\"Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?'], ['Czy', 'nie,', 'czy', 'nie?'], [''], ['Stokrotka', 'się', 'zgodziła'], ['I', 'poszli', 'w', 'ciemny', 'las,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['w', 'pokrzywy', 'wlazł.'], [''], ['A', 'ona,', 'ona,', 'ona,'], ['Cóż', 'biedna', 'robić', 'ma,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje', 'się:', 'ha,', 'ha,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje:', 'się', 'ha,', 'ha,'], ['ha,', 'ha,', 'ha,', 'ha.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = None\n",
    "list_of_verses = re.split(\"\\n\", song)\n",
    "sentences = [re.split(RE_SPACES, verse) for verse in list_of_verses]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając tekst podzielony na zdania a zdania na tokeny, możemy nauczyć model word2vec.\n",
    "\n",
    "**Zad. 2: Naucz model word2vec. [Sprawdź](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) za co odpowiedzialne są parametry `min_count` i `iter`. Jakie inne parametry mogą być przydatne?**<br>\n",
    "Ignoruje wszystkie włowa występujące rzadziej niż `min_count`.<br> \n",
    "`iter` aktualnie `epochs` definuje liczbę iteracji dla jednego korpusu.<br>\n",
    "<br>\n",
    "Inne wybrane parametry:<br>\n",
    "`size` - liczba wymiarów wektora słowa<br>\n",
    "`window` - maksymalna odległość pomiędzy aktualnym i przewidywalnym słowem w zdaniu (<i>sentence</i>)<br>\n",
    "`sg` - algorytm uczący `1` dla `skip-gram`, inne dla `CBOW`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 20:07:38,389 : INFO : collecting all words and their counts\n",
      "2020-12-29 20:07:38,391 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-29 20:07:38,392 : INFO : collected 80 word types from a corpus of 144 raw words and 39 sentences\n",
      "2020-12-29 20:07:38,393 : INFO : Loading a fresh vocabulary\n",
      "2020-12-29 20:07:38,393 : INFO : effective_min_count=1 retains 80 unique words (100% of original 80, drops 0)\n",
      "2020-12-29 20:07:38,394 : INFO : effective_min_count=1 leaves 144 word corpus (100% of original 144, drops 0)\n",
      "2020-12-29 20:07:38,396 : INFO : deleting the raw counts dictionary of 80 items\n",
      "2020-12-29 20:07:38,396 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2020-12-29 20:07:38,397 : INFO : downsampling leaves estimated 50 word corpus (35.2% of prior 144)\n",
      "2020-12-29 20:07:38,398 : INFO : estimated required memory for 80 words and 100 dimensions: 104000 bytes\n",
      "2020-12-29 20:07:38,400 : INFO : resetting layer weights\n",
      "2020-12-29 20:07:38,428 : INFO : training model with 3 workers on 80 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-29 20:07:38,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:38,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:38,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:38,435 : INFO : EPOCH - 1 : training on 144 raw words (48 effective words) took 0.0s, 11389 effective words/s\n",
      "2020-12-29 20:07:38,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:38,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:38,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:38,446 : INFO : EPOCH - 2 : training on 144 raw words (53 effective words) took 0.0s, 9308 effective words/s\n",
      "2020-12-29 20:07:38,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:38,451 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:38,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:38,453 : INFO : EPOCH - 3 : training on 144 raw words (47 effective words) took 0.0s, 13018 effective words/s\n",
      "2020-12-29 20:07:38,458 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:38,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:38,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:38,462 : INFO : EPOCH - 4 : training on 144 raw words (62 effective words) took 0.0s, 14439 effective words/s\n",
      "2020-12-29 20:07:38,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:38,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:38,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:38,469 : INFO : EPOCH - 5 : training on 144 raw words (51 effective words) took 0.0s, 16983 effective words/s\n",
      "2020-12-29 20:07:38,470 : INFO : training on a 720 raw words (261 effective words) took 0.0s, 6302 effective words/s\n",
      "2020-12-29 20:07:38,471 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-12-29 20:07:38,473 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-12-29 20:07:38,475 : WARNING : vectors for words {'las', 'gaj'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=80, size=100, alpha=0.025)\n",
      "<gensim.models.word2vec.Word2VecVocab object at 0x7fcbe1de5be0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lilatee/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'harcerz'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=5, min_count=1)\n",
    "print(model)\n",
    "print(model.vocabulary)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model jest niezwykle mały i niezbyt praktyczny, ale pozwolił pokazać podstawę uczenia word2vec. Przy większych korpusach tekstowych wczytywanie do pamięci wielkich tablic nie byłoby najlepszym pomysłem. Na szczęście implementacja word2vec w gensim potrafi przetwarzać dane przyrostowo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie strumieniowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast wczytywać wszystkie dokumenty naraz można robić to partiami, bo sieci neuronowe (w tym word2vec) potrafią douczać się przyrostowo. Do douczania przyrostowego świetnie nada się pythonowy iterator lub generator. Jeśli nie kojarzysz na czym polega działanie iteratorów i generatorów, zobacz jak [wyjaśnia to Radim Rehurek](https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/).\n",
    "\n",
    "Zasymulujmy zdania/wersy/tweety przechowywane w osobnych plikach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open, os\n",
    "\n",
    "if not os.path.exists('./data/'):\n",
    "    os.makedirs('./data/')\n",
    "\n",
    "filenames = ['./data/f' + str(i) +'.txt' for i in range(39)]\n",
    "\n",
    "if sentences is not None:\n",
    "    for i, fname in enumerate(filenames):\n",
    "        with smart_open.smart_open(fname, 'w') as fout:\n",
    "            for line in sentences[i]:\n",
    "                fout.write(line + ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3: Mając powyższy zbiór dokumentów tekstowych, stwórz metodę która będzie \"leniwie\" iterowała przez zasymulowany zbiór danych. Podczas iterowania usuń znaki interpunkcyjne i zmień wszystkie litery na małe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 20:07:41,840 : INFO : collecting all words and their counts\n",
      "2020-12-29 20:07:41,846 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-29 20:07:41,959 : INFO : collected 66 word types from a corpus of 183 raw words and 39 sentences\n",
      "2020-12-29 20:07:41,960 : INFO : Loading a fresh vocabulary\n",
      "2020-12-29 20:07:41,961 : INFO : effective_min_count=1 retains 66 unique words (100% of original 66, drops 0)\n",
      "2020-12-29 20:07:41,962 : INFO : effective_min_count=1 leaves 183 word corpus (100% of original 183, drops 0)\n",
      "2020-12-29 20:07:41,963 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2020-12-29 20:07:41,964 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2020-12-29 20:07:41,964 : INFO : downsampling leaves estimated 53 word corpus (29.5% of prior 183)\n",
      "2020-12-29 20:07:41,965 : INFO : estimated required memory for 66 words and 100 dimensions: 85800 bytes\n",
      "2020-12-29 20:07:41,966 : INFO : resetting layer weights\n",
      "2020-12-29 20:07:41,989 : INFO : training model with 3 workers on 66 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-29 20:07:42,074 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,077 : INFO : EPOCH - 1 : training on 183 raw words (51 effective words) took 0.1s, 603 effective words/s\n",
      "2020-12-29 20:07:42,176 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,178 : INFO : EPOCH - 2 : training on 183 raw words (57 effective words) took 0.1s, 578 effective words/s\n",
      "2020-12-29 20:07:42,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,289 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,290 : INFO : EPOCH - 3 : training on 183 raw words (46 effective words) took 0.1s, 436 effective words/s\n",
      "2020-12-29 20:07:42,397 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,399 : INFO : EPOCH - 4 : training on 183 raw words (41 effective words) took 0.1s, 391 effective words/s\n",
      "2020-12-29 20:07:42,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,499 : INFO : EPOCH - 5 : training on 183 raw words (53 effective words) took 0.1s, 556 effective words/s\n",
      "2020-12-29 20:07:42,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,583 : INFO : EPOCH - 6 : training on 183 raw words (55 effective words) took 0.1s, 674 effective words/s\n",
      "2020-12-29 20:07:42,681 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,683 : INFO : EPOCH - 7 : training on 183 raw words (54 effective words) took 0.1s, 559 effective words/s\n",
      "2020-12-29 20:07:42,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,771 : INFO : EPOCH - 8 : training on 183 raw words (63 effective words) took 0.1s, 741 effective words/s\n",
      "2020-12-29 20:07:42,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,861 : INFO : EPOCH - 9 : training on 183 raw words (59 effective words) took 0.1s, 682 effective words/s\n",
      "2020-12-29 20:07:42,961 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:42,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:42,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:42,964 : INFO : EPOCH - 10 : training on 183 raw words (48 effective words) took 0.1s, 479 effective words/s\n",
      "2020-12-29 20:07:42,965 : INFO : training on a 1830 raw words (527 effective words) took 1.0s, 540 effective words/s\n",
      "2020-12-29 20:07:42,966 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-12-29 20:07:42,968 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=66, size=100, alpha=0.025)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'harcerz'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            if fname.endswith('.txt'):\n",
    "                for line in open(os.path.join(self.dirname, fname)):\n",
    "                    yield line.translate(table).lower().split(\" \") \n",
    "\n",
    "# Do odkomentowania:\n",
    "sentences = MySentences('./data/')\n",
    "model = gensim.models.Word2Vec(sentences, iter=10, min_count=1)\n",
    "print(model)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trochę więcej danych i przykłady zastosowań\n",
    "\n",
    "Jak wspomniano wcześniej powyższa piosenka jest zbyt krótka by stworzyć przekonujący model podobieństwa między słowami. Przejdziemy teraz na język angielski i wykorzystamy korpus dołączony do biblioteki `gensim`. Ten korpus nie jest jeszcze duży, więc wyniki nie będą rewelacyjne. Potrzeba > 500 tys. słów, żeby oczekiwać rozsądnych wyników dla ogólnych zapytań, ale przy specjalistycznych zastosowaniach korpusy niekoniecznie muszą być takie duże.\n",
    "\n",
    "**Zad. 4: Korzystając ze zdobytej wiedzy na temat iteratorów, uzupełnij poniższy kod.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep\n",
    "lee_train_file = test_data_dir + 'lee_background.cor'\n",
    "\n",
    "class MyText(object):\n",
    "    def __iter__(self):\n",
    "        for line in open(lee_train_file):\n",
    "            # Załóż, że każda linia to dokument, zmień litery na małe,\n",
    "            line = line.lower()\n",
    "            # usuń podstawowe znaki interpunkcyjne i podziel według białych znaków\n",
    "            yield line.translate(table).lower().split(\" \")\n",
    "\n",
    "sentences = MyText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Naucz model word2vec o rozmiarze 200, przez 100 epok, usuwając słowa występującerzadziej niż 5 razy. Wynik przypisz do zmiennej `model`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 20:07:45,760 : INFO : collecting all words and their counts\n",
      "2020-12-29 20:07:45,762 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-29 20:07:45,798 : INFO : collected 7587 word types from a corpus of 60244 raw words and 300 sentences\n",
      "2020-12-29 20:07:45,800 : INFO : Loading a fresh vocabulary\n",
      "2020-12-29 20:07:45,806 : INFO : effective_min_count=5 retains 1792 unique words (23% of original 7587, drops 5795)\n",
      "2020-12-29 20:07:45,807 : INFO : effective_min_count=5 leaves 50650 word corpus (84% of original 60244, drops 9594)\n",
      "2020-12-29 20:07:45,817 : INFO : deleting the raw counts dictionary of 7587 items\n",
      "2020-12-29 20:07:45,820 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-12-29 20:07:45,821 : INFO : downsampling leaves estimated 36474 word corpus (72.0% of prior 50650)\n",
      "2020-12-29 20:07:45,824 : INFO : estimated required memory for 1792 words and 200 dimensions: 3763200 bytes\n",
      "2020-12-29 20:07:45,825 : INFO : resetting layer weights\n",
      "2020-12-29 20:07:46,150 : INFO : training model with 3 workers on 1792 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-29 20:07:46,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,199 : INFO : EPOCH - 1 : training on 60244 raw words (36480 effective words) took 0.0s, 799884 effective words/s\n",
      "2020-12-29 20:07:46,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,254 : INFO : EPOCH - 2 : training on 60244 raw words (36646 effective words) took 0.1s, 717300 effective words/s\n",
      "2020-12-29 20:07:46,294 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,302 : INFO : EPOCH - 3 : training on 60244 raw words (36503 effective words) took 0.0s, 793606 effective words/s\n",
      "2020-12-29 20:07:46,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,355 : INFO : EPOCH - 4 : training on 60244 raw words (36489 effective words) took 0.0s, 766969 effective words/s\n",
      "2020-12-29 20:07:46,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,404 : INFO : EPOCH - 5 : training on 60244 raw words (36379 effective words) took 0.0s, 787847 effective words/s\n",
      "2020-12-29 20:07:46,445 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,452 : INFO : EPOCH - 6 : training on 60244 raw words (36565 effective words) took 0.0s, 802931 effective words/s\n",
      "2020-12-29 20:07:46,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,496 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,500 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,502 : INFO : EPOCH - 7 : training on 60244 raw words (36506 effective words) took 0.0s, 763756 effective words/s\n",
      "2020-12-29 20:07:46,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,563 : INFO : EPOCH - 8 : training on 60244 raw words (36410 effective words) took 0.1s, 637503 effective words/s\n",
      "2020-12-29 20:07:46,603 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,611 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,611 : INFO : EPOCH - 9 : training on 60244 raw words (36515 effective words) took 0.0s, 823764 effective words/s\n",
      "2020-12-29 20:07:46,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,659 : INFO : EPOCH - 10 : training on 60244 raw words (36475 effective words) took 0.0s, 797784 effective words/s\n",
      "2020-12-29 20:07:46,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,710 : INFO : EPOCH - 11 : training on 60244 raw words (36488 effective words) took 0.0s, 754026 effective words/s\n",
      "2020-12-29 20:07:46,751 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,758 : INFO : EPOCH - 12 : training on 60244 raw words (36469 effective words) took 0.0s, 806050 effective words/s\n",
      "2020-12-29 20:07:46,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,806 : INFO : EPOCH - 13 : training on 60244 raw words (36355 effective words) took 0.0s, 783518 effective words/s\n",
      "2020-12-29 20:07:46,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,858 : INFO : EPOCH - 14 : training on 60244 raw words (36529 effective words) took 0.0s, 744645 effective words/s\n",
      "2020-12-29 20:07:46,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,905 : INFO : EPOCH - 15 : training on 60244 raw words (36537 effective words) took 0.0s, 829969 effective words/s\n",
      "2020-12-29 20:07:46,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:46,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:46,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:46,960 : INFO : EPOCH - 16 : training on 60244 raw words (36370 effective words) took 0.1s, 693799 effective words/s\n",
      "2020-12-29 20:07:47,003 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,018 : INFO : EPOCH - 17 : training on 60244 raw words (36535 effective words) took 0.1s, 667740 effective words/s\n",
      "2020-12-29 20:07:47,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,068 : INFO : EPOCH - 18 : training on 60244 raw words (36451 effective words) took 0.0s, 780422 effective words/s\n",
      "2020-12-29 20:07:47,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,122 : INFO : EPOCH - 19 : training on 60244 raw words (36487 effective words) took 0.1s, 709360 effective words/s\n",
      "2020-12-29 20:07:47,160 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,171 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,172 : INFO : EPOCH - 20 : training on 60244 raw words (36373 effective words) took 0.0s, 771610 effective words/s\n",
      "2020-12-29 20:07:47,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,230 : INFO : EPOCH - 21 : training on 60244 raw words (36516 effective words) took 0.1s, 668414 effective words/s\n",
      "2020-12-29 20:07:47,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,293 : INFO : EPOCH - 22 : training on 60244 raw words (36400 effective words) took 0.1s, 636805 effective words/s\n",
      "2020-12-29 20:07:47,333 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,339 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,341 : INFO : EPOCH - 23 : training on 60244 raw words (36446 effective words) took 0.0s, 828763 effective words/s\n",
      "2020-12-29 20:07:47,380 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,389 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,390 : INFO : EPOCH - 24 : training on 60244 raw words (36446 effective words) took 0.0s, 791631 effective words/s\n",
      "2020-12-29 20:07:47,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,434 : INFO : EPOCH - 25 : training on 60244 raw words (36512 effective words) took 0.0s, 860694 effective words/s\n",
      "2020-12-29 20:07:47,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,477 : INFO : EPOCH - 26 : training on 60244 raw words (36457 effective words) took 0.0s, 903163 effective words/s\n",
      "2020-12-29 20:07:47,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,522 : INFO : EPOCH - 27 : training on 60244 raw words (36529 effective words) took 0.0s, 853521 effective words/s\n",
      "2020-12-29 20:07:47,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,566 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,571 : INFO : EPOCH - 28 : training on 60244 raw words (36487 effective words) took 0.0s, 811686 effective words/s\n",
      "2020-12-29 20:07:47,611 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,616 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,622 : INFO : EPOCH - 29 : training on 60244 raw words (36454 effective words) took 0.0s, 762299 effective words/s\n",
      "2020-12-29 20:07:47,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,675 : INFO : EPOCH - 30 : training on 60244 raw words (36428 effective words) took 0.1s, 717895 effective words/s\n",
      "2020-12-29 20:07:47,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,725 : INFO : EPOCH - 31 : training on 60244 raw words (36444 effective words) took 0.0s, 777756 effective words/s\n",
      "2020-12-29 20:07:47,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,775 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,778 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,779 : INFO : EPOCH - 32 : training on 60244 raw words (36463 effective words) took 0.1s, 702422 effective words/s\n",
      "2020-12-29 20:07:47,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,826 : INFO : EPOCH - 33 : training on 60244 raw words (36515 effective words) took 0.0s, 801209 effective words/s\n",
      "2020-12-29 20:07:47,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,882 : INFO : EPOCH - 34 : training on 60244 raw words (36475 effective words) took 0.1s, 682549 effective words/s\n",
      "2020-12-29 20:07:47,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,925 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,929 : INFO : EPOCH - 35 : training on 60244 raw words (36370 effective words) took 0.0s, 814016 effective words/s\n",
      "2020-12-29 20:07:47,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:47,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:47,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:47,978 : INFO : EPOCH - 36 : training on 60244 raw words (36459 effective words) took 0.0s, 788506 effective words/s\n",
      "2020-12-29 20:07:48,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,028 : INFO : EPOCH - 37 : training on 60244 raw words (36534 effective words) took 0.0s, 785038 effective words/s\n",
      "2020-12-29 20:07:48,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,073 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,077 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,078 : INFO : EPOCH - 38 : training on 60244 raw words (36501 effective words) took 0.0s, 786944 effective words/s\n",
      "2020-12-29 20:07:48,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,123 : INFO : EPOCH - 39 : training on 60244 raw words (36510 effective words) took 0.0s, 862399 effective words/s\n",
      "2020-12-29 20:07:48,169 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,175 : INFO : EPOCH - 40 : training on 60244 raw words (36454 effective words) took 0.0s, 743042 effective words/s\n",
      "2020-12-29 20:07:48,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,227 : INFO : EPOCH - 41 : training on 60244 raw words (36566 effective words) took 0.0s, 734079 effective words/s\n",
      "2020-12-29 20:07:48,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,284 : INFO : EPOCH - 42 : training on 60244 raw words (36532 effective words) took 0.1s, 668187 effective words/s\n",
      "2020-12-29 20:07:48,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,337 : INFO : EPOCH - 43 : training on 60244 raw words (36495 effective words) took 0.1s, 719604 effective words/s\n",
      "2020-12-29 20:07:48,376 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,380 : INFO : EPOCH - 44 : training on 60244 raw words (36520 effective words) took 0.0s, 889866 effective words/s\n",
      "2020-12-29 20:07:48,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,427 : INFO : EPOCH - 45 : training on 60244 raw words (36498 effective words) took 0.0s, 828256 effective words/s\n",
      "2020-12-29 20:07:48,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,468 : INFO : EPOCH - 46 : training on 60244 raw words (36469 effective words) took 0.0s, 956554 effective words/s\n",
      "2020-12-29 20:07:48,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,508 : INFO : EPOCH - 47 : training on 60244 raw words (36473 effective words) took 0.0s, 954673 effective words/s\n",
      "2020-12-29 20:07:48,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,552 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,556 : INFO : EPOCH - 48 : training on 60244 raw words (36528 effective words) took 0.0s, 809601 effective words/s\n",
      "2020-12-29 20:07:48,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,604 : INFO : EPOCH - 49 : training on 60244 raw words (36498 effective words) took 0.0s, 835040 effective words/s\n",
      "2020-12-29 20:07:48,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,650 : INFO : EPOCH - 50 : training on 60244 raw words (36404 effective words) took 0.0s, 841874 effective words/s\n",
      "2020-12-29 20:07:48,683 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,690 : INFO : EPOCH - 51 : training on 60244 raw words (36377 effective words) took 0.0s, 983646 effective words/s\n",
      "2020-12-29 20:07:48,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,730 : INFO : EPOCH - 52 : training on 60244 raw words (36579 effective words) took 0.0s, 979992 effective words/s\n",
      "2020-12-29 20:07:48,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,769 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,776 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,777 : INFO : EPOCH - 53 : training on 60244 raw words (36629 effective words) took 0.0s, 824550 effective words/s\n",
      "2020-12-29 20:07:48,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,825 : INFO : EPOCH - 54 : training on 60244 raw words (36356 effective words) took 0.0s, 792132 effective words/s\n",
      "2020-12-29 20:07:48,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,866 : INFO : EPOCH - 55 : training on 60244 raw words (36290 effective words) took 0.0s, 1120875 effective words/s\n",
      "2020-12-29 20:07:48,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,910 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,911 : INFO : EPOCH - 56 : training on 60244 raw words (36562 effective words) took 0.0s, 858227 effective words/s\n",
      "2020-12-29 20:07:48,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:48,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:48,958 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:48,959 : INFO : EPOCH - 57 : training on 60244 raw words (36506 effective words) took 0.0s, 835682 effective words/s\n",
      "2020-12-29 20:07:49,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,004 : INFO : EPOCH - 58 : training on 60244 raw words (36515 effective words) took 0.0s, 846807 effective words/s\n",
      "2020-12-29 20:07:49,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,050 : INFO : EPOCH - 59 : training on 60244 raw words (36472 effective words) took 0.0s, 847997 effective words/s\n",
      "2020-12-29 20:07:49,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,101 : INFO : EPOCH - 60 : training on 60244 raw words (36402 effective words) took 0.0s, 746774 effective words/s\n",
      "2020-12-29 20:07:49,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,145 : INFO : EPOCH - 61 : training on 60244 raw words (36470 effective words) took 0.0s, 866293 effective words/s\n",
      "2020-12-29 20:07:49,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,189 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,190 : INFO : EPOCH - 62 : training on 60244 raw words (36536 effective words) took 0.0s, 869551 effective words/s\n",
      "2020-12-29 20:07:49,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,230 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,233 : INFO : EPOCH - 63 : training on 60244 raw words (36517 effective words) took 0.0s, 876361 effective words/s\n",
      "2020-12-29 20:07:49,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,279 : INFO : EPOCH - 64 : training on 60244 raw words (36414 effective words) took 0.0s, 827798 effective words/s\n",
      "2020-12-29 20:07:49,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,321 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,328 : INFO : EPOCH - 65 : training on 60244 raw words (36529 effective words) took 0.0s, 806131 effective words/s\n",
      "2020-12-29 20:07:49,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,371 : INFO : EPOCH - 66 : training on 60244 raw words (36651 effective words) took 0.0s, 895922 effective words/s\n",
      "2020-12-29 20:07:49,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,413 : INFO : EPOCH - 67 : training on 60244 raw words (36470 effective words) took 0.0s, 921099 effective words/s\n",
      "2020-12-29 20:07:49,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,459 : INFO : EPOCH - 68 : training on 60244 raw words (36459 effective words) took 0.0s, 839178 effective words/s\n",
      "2020-12-29 20:07:49,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,511 : INFO : EPOCH - 69 : training on 60244 raw words (36373 effective words) took 0.0s, 751786 effective words/s\n",
      "2020-12-29 20:07:49,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,553 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,554 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,555 : INFO : EPOCH - 70 : training on 60244 raw words (36422 effective words) took 0.0s, 868609 effective words/s\n",
      "2020-12-29 20:07:49,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,599 : INFO : EPOCH - 71 : training on 60244 raw words (36626 effective words) took 0.0s, 894264 effective words/s\n",
      "2020-12-29 20:07:49,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,642 : INFO : EPOCH - 72 : training on 60244 raw words (36502 effective words) took 0.0s, 890969 effective words/s\n",
      "2020-12-29 20:07:49,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,680 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,683 : INFO : EPOCH - 73 : training on 60244 raw words (36527 effective words) took 0.0s, 940792 effective words/s\n",
      "2020-12-29 20:07:49,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,724 : INFO : EPOCH - 74 : training on 60244 raw words (36489 effective words) took 0.0s, 979897 effective words/s\n",
      "2020-12-29 20:07:49,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,763 : INFO : EPOCH - 75 : training on 60244 raw words (36364 effective words) took 0.0s, 977217 effective words/s\n",
      "2020-12-29 20:07:49,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,810 : INFO : EPOCH - 76 : training on 60244 raw words (36412 effective words) took 0.0s, 824303 effective words/s\n",
      "2020-12-29 20:07:49,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,852 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,853 : INFO : EPOCH - 77 : training on 60244 raw words (36464 effective words) took 0.0s, 911354 effective words/s\n",
      "2020-12-29 20:07:49,888 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,894 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,898 : INFO : EPOCH - 78 : training on 60244 raw words (36337 effective words) took 0.0s, 845129 effective words/s\n",
      "2020-12-29 20:07:49,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,943 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,947 : INFO : EPOCH - 79 : training on 60244 raw words (36436 effective words) took 0.0s, 814351 effective words/s\n",
      "2020-12-29 20:07:49,983 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:49,991 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:49,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:49,995 : INFO : EPOCH - 80 : training on 60244 raw words (36570 effective words) took 0.0s, 814029 effective words/s\n",
      "2020-12-29 20:07:50,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,037 : INFO : EPOCH - 81 : training on 60244 raw words (36486 effective words) took 0.0s, 938530 effective words/s\n",
      "2020-12-29 20:07:50,070 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,077 : INFO : EPOCH - 82 : training on 60244 raw words (36609 effective words) took 0.0s, 976602 effective words/s\n",
      "2020-12-29 20:07:50,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,113 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,115 : INFO : EPOCH - 83 : training on 60244 raw words (36418 effective words) took 0.0s, 993236 effective words/s\n",
      "2020-12-29 20:07:50,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,154 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,156 : INFO : EPOCH - 84 : training on 60244 raw words (36366 effective words) took 0.0s, 955537 effective words/s\n",
      "2020-12-29 20:07:50,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,199 : INFO : EPOCH - 85 : training on 60244 raw words (36443 effective words) took 0.0s, 911948 effective words/s\n",
      "2020-12-29 20:07:50,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,247 : INFO : EPOCH - 86 : training on 60244 raw words (36360 effective words) took 0.0s, 796171 effective words/s\n",
      "2020-12-29 20:07:50,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,288 : INFO : EPOCH - 87 : training on 60244 raw words (36452 effective words) took 0.0s, 953003 effective words/s\n",
      "2020-12-29 20:07:50,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,332 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,332 : INFO : EPOCH - 88 : training on 60244 raw words (36501 effective words) took 0.0s, 891320 effective words/s\n",
      "2020-12-29 20:07:50,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,378 : INFO : EPOCH - 89 : training on 60244 raw words (36464 effective words) took 0.0s, 853161 effective words/s\n",
      "2020-12-29 20:07:50,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,417 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,419 : INFO : EPOCH - 90 : training on 60244 raw words (36413 effective words) took 0.0s, 940406 effective words/s\n",
      "2020-12-29 20:07:50,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,464 : INFO : EPOCH - 91 : training on 60244 raw words (36404 effective words) took 0.0s, 860769 effective words/s\n",
      "2020-12-29 20:07:50,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,509 : INFO : EPOCH - 92 : training on 60244 raw words (36369 effective words) took 0.0s, 849439 effective words/s\n",
      "2020-12-29 20:07:50,549 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,554 : INFO : EPOCH - 93 : training on 60244 raw words (36388 effective words) took 0.0s, 855560 effective words/s\n",
      "2020-12-29 20:07:50,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,600 : INFO : EPOCH - 94 : training on 60244 raw words (36446 effective words) took 0.0s, 848157 effective words/s\n",
      "2020-12-29 20:07:50,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,650 : INFO : EPOCH - 95 : training on 60244 raw words (36455 effective words) took 0.0s, 776666 effective words/s\n",
      "2020-12-29 20:07:50,688 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,690 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,695 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,696 : INFO : EPOCH - 96 : training on 60244 raw words (36365 effective words) took 0.0s, 848777 effective words/s\n",
      "2020-12-29 20:07:50,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,738 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,748 : INFO : EPOCH - 97 : training on 60244 raw words (36299 effective words) took 0.0s, 746879 effective words/s\n",
      "2020-12-29 20:07:50,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,798 : INFO : EPOCH - 98 : training on 60244 raw words (36493 effective words) took 0.0s, 797928 effective words/s\n",
      "2020-12-29 20:07:50,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,845 : INFO : EPOCH - 99 : training on 60244 raw words (36481 effective words) took 0.0s, 829042 effective words/s\n",
      "2020-12-29 20:07:50,886 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-29 20:07:50,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-29 20:07:50,888 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-29 20:07:50,889 : INFO : EPOCH - 100 : training on 60244 raw words (36455 effective words) took 0.0s, 882337 effective words/s\n",
      "2020-12-29 20:07:50,890 : INFO : training on a 6024400 raw words (3646868 effective words) took 4.7s, 769638 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=1792, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=100, min_count=5, size=200)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6: Odkomentuj poniższe linie i zobacz jak można wykorzystać uzyskany model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 20:07:59,024 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('stage', 0.48585766553878784)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['human', 'crime'], negative=['party'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 20:08:07,597 : WARNING : vectors for words {'input', 'lunch', 'cat'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"input is lunch he sentence cat\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.022005534\n",
      "0.2225884\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('human', 'tree'))\n",
    "print(model.wv.similarity('crime', 'murder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwagi dodatkowe:**\n",
    "+ uczenie modelu można zrównoleglić, ale trzeba doinstalować [Cythona](http://cython.org/)\n",
    "+ wytrenowany model można łatwo zapisać do pliku za pomocą: `model.save(path)`\n",
    "+ równie łatwo można go później wczytać: `model = gensim.models.Word2Vec.load(path)`\n",
    "+ ponieważ uczenie jest przyrostowe, można łatwo rozszerzyć istniejący słownik i douczyć model na nowych zdaniach:\n",
    "```\n",
    "model = gensim.models.Word2Vec.load(path)\n",
    "more_sentences = [['Advanced', 'users', 'can', 'load', 'a', 'model', 'and', 'continue', \n",
    "                  'training', 'it', 'with', 'more', 'sentences']]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystanie gotowego modelu do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Póki co sami trenowaliśmy word2vec i to na niedużych zbiorach danych. Na szczęście są już gotowe modele (przynajmniej dla języka angielskiego) nauczone na miliardach dokumentów i zawierające miliony słów. Przydatna lista takich modeli (wraz z kodem tworzącym usługę sieciową wykorzystującą model...) pod adresem: https://github.com/3Top/word2vec-api.\n",
    "\n",
    "**Zad. 7: Pobierz korpus Google News i zapisz pobrany plik do folderu data. Następnie wykonaj poniższy kod. Ta operacja zajmie jakieś 3-4 minuty i zużyje ok. 4 GB RAMU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-30 11:20:46,334 : INFO : loading projection weights from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2020-12-30 11:22:59,673 : INFO : loaded (3000000, 300) matrix from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2020-12-30 11:22:59,675 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 11.5 s, total: 1min 42s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 8: Zobacz jak działa model nauczony na tak dużym korpusie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.32413527\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity('woman', 'man'))\n",
    "print(wv.similarity('woman', 'cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, super. Mam świetny model, mogę nim podpowiadać słowa, wynajdować niepasujące elementy, uzupełniać zdania, znajdować synonimy, itd. Ale czy da się to jakoś wykorzystać do klasyfikacji? word2vec ma wektor na każde słowo - jak z tego zrobić wektor na ciąg słów?\n",
    "\n",
    "**Odpowiedź: można uśrednić znaczenie słów w dokuemncie poprzez zsumowanie wektorów wszystkich słów.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo szybko spróbujemy zastosować to podejście do predykcji gatunku filmu na podstawie jego opisu. Poniżej kod wczytujący ciekawy zbiór danych oraz pokazujący jakie ma klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  movieId                                               plot  \\\n",
      "0           0        1  A little boy named Andy loves to be in his roo...   \n",
      "1           1        2  When two kids find and play a magical board ga...   \n",
      "2           2        3  Things don't seem to change much in Wabasha Co...   \n",
      "3           3        6  Hunters and their prey--Neil and his professio...   \n",
      "4           4        7  An ugly duckling having undergone a remarkable...   \n",
      "\n",
      "         tag  \n",
      "0  animation  \n",
      "1    fantasy  \n",
      "2     comedy  \n",
      "3     action  \n",
      "4    romance  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('data/tagged_plots_movielens.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "df.tag.value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szybko dzielimy dane na zbiór uczący i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizujemy dane i wyliczamy reprezentację wektorową (za pomocą zsumowanych wektorów słów wrod2vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczymy i testujemy klasyfikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lilatee/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, train_data['tag'])\n",
    "predicted = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrzymy jak nam poszło:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.5390946502057613\n",
      "Macierz pomyłek\n",
      " [[23  2 10  0  1  6]\n",
      " [ 3 10  8  3  4  3]\n",
      " [ 2  5 55  2 18  4]\n",
      " [ 3  4  4  4  0  1]\n",
      " [ 4  0 12  1 16  2]\n",
      " [ 5  0  3  0  2 23]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.tag, predicted))\n",
    "cm = confusion_matrix(test_data.tag, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak na brak porządnego przetwarzania wstępnego, nie jest to zły wynik. Mam nadzieję, że ten przykład pokazał jak można wykorzystać word2vec do tworzenia atrybutów dla problemów klasyfikacyjnych."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
